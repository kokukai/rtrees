{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.rendered_html { font-size: 16px; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\")) # Increase cell width\n",
    "display(HTML(\"<style>.rendered_html { font-size: 16px; }</style>\")) # Increase font size\n",
    "\n",
    "# Larger figures\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import auc, roc_curve, f1_score, accuracy_score, precision_recall_curve, confusion_matrix, classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice #2\n",
    "\n",
    "Regression trees with Titanic data file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable description:\n",
    "\n",
    "- **survived:\tSurvival (target variable) - 0 = No, 1 = Yes**\n",
    "- pclass:\tTicket class - 1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "- sex:\t    Sex\n",
    "- age:\t    Age in years\n",
    "- sibsp:\t# of siblings / spouses aboard the Titanic\n",
    "- parch:\t# of parents / children aboard the Titanic\n",
    "- ticket:\tTicket number\n",
    "- fare:\t    Passenger fare\n",
    "- cabin:\tCabin number\n",
    "- embarked:\tPort of Embarkation - C = Cherbourg, Q = Queenstown, S = Southampton\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the dataset and review null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived  sex      age  sibsp  parch  ticket      fare    cabin  \\\n",
       "0       1         1    1  29.0000      0      0   24160  211.3375       B5   \n",
       "1       1         1    0   0.9167      1      2  113781  151.5500  C22 C26   \n",
       "2       1         0    1   2.0000      1      2  113781  151.5500  C22 C26   \n",
       "3       1         0    0  30.0000      1      2  113781  151.5500  C22 C26   \n",
       "4       1         0    1  25.0000      1      2  113781  151.5500  C22 C26   \n",
       "\n",
       "   embarked  \n",
       "0       2.0  \n",
       "1       2.0  \n",
       "2       2.0  \n",
       "3       2.0  \n",
       "4       2.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openpyxl\n",
    "\n",
    "# Red data\n",
    "filename = 'titanic.xlsx'\n",
    "df = pd.read_excel(filename, 1) #it has two sheets, we load the 2nd one\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records and variables:  (1309, 10)\n",
      "Column names:  ['pclass', 'survived', 'sex', 'age', 'sibsp', 'parch', 'ticket', 'fare', 'cabin', 'embarked']\n"
     ]
    }
   ],
   "source": [
    "print (\"Records and variables: \", df.shape)\n",
    "print (\"Column names: \", df.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass         0\n",
       "survived       0\n",
       "sex            0\n",
       "age          263\n",
       "sibsp          0\n",
       "parch          0\n",
       "ticket         0\n",
       "fare           1\n",
       "cabin       1014\n",
       "embarked       2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() #null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 variables with null values, mostly cabin and age. <BR>\n",
    "We can discard cabin since it appears to be meaningless (and also ticket). <BR> \n",
    "We will need to delete records with missing values, otherwise the model will fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B5', 'C22 C26', 'E12', 'D7', 'A36', 'C101', nan, 'C62 C64', 'B35',\n",
       "       'A23', 'B58 B60', 'D15', 'C6', 'D35', 'C148', 'C97', 'B49', 'C99',\n",
       "       'C52', 'T', 'A31', 'C7', 'C103', 'D22', 'E33', 'A21', 'B10', 'B4',\n",
       "       'E40', 'B38', 'E24', 'B51 B53 B55', 'B96 B98', 'C46', 'E31', 'E8',\n",
       "       'B61', 'B77', 'A9', 'C89', 'A14', 'E58', 'E49', 'E52', 'E45',\n",
       "       'B22', 'B26', 'C85', 'E17', 'B71', 'B20', 'A34', 'C86', 'A16',\n",
       "       'A20', 'A18', 'C54', 'C45', 'D20', 'A29', 'C95', 'E25', 'C111',\n",
       "       'C23 C25 C27', 'E36', 'D34', 'D40', 'B39', 'B41', 'B102', 'C123',\n",
       "       'E63', 'C130', 'B86', 'C92', 'A5', 'C51', 'B42', 'C91', 'C125',\n",
       "       'D10 D12', 'B82 B84', 'E50', 'D33', 'C83', 'B94', 'D49', 'D45',\n",
       "       'B69', 'B11', 'E46', 'C39', 'B18', 'D11', 'C93', 'B28', 'C49',\n",
       "       'B52 B54 B56', 'E60', 'C132', 'B37', 'D21', 'D19', 'C124', 'D17',\n",
       "       'B101', 'D28', 'D6', 'D9', 'B80', 'C106', 'B79', 'C47', 'D30',\n",
       "       'C90', 'E38', 'C78', 'C30', 'C118', 'D36', 'D48', 'D47', 'C105',\n",
       "       'B36', 'B30', 'D43', 'B24', 'C2', 'C65', 'B73', 'C104', 'C110',\n",
       "       'C50', 'B3', 'A24', 'A32', 'A11', 'A10', 'B57 B59 B63 B66', 'C28',\n",
       "       'E44', 'A26', 'A6', 'A7', 'C31', 'A19', 'B45', 'E34', 'B78', 'B50',\n",
       "       'C87', 'C116', 'C55 C57', 'D50', 'E68', 'E67', 'C126', 'C68',\n",
       "       'C70', 'C53', 'B19', 'D46', 'D37', 'D26', 'C32', 'C80', 'C82',\n",
       "       'C128', 'E39 E41', 'D', 'F4', 'D56', 'F33', 'E101', 'E77', 'F2',\n",
       "       'D38', 'F', 'F G63', 'F E57', 'F E46', 'F G73', 'E121', 'F E69',\n",
       "       'E10', 'G6', 'F38'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cabin'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# droppping cabin and ticket\n",
    "df.drop(labels=['cabin', 'ticket'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show % of records from each of the survived class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class '1': 38.20%\n",
      "Class '0': 61.80%\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def class_perc(data):\n",
    "    lendata = len(data)\n",
    "    classes = Counter(data)\n",
    "    \n",
    "    for sclass, freq in classes.items():\n",
    "        perc = (freq / lendata) * 100\n",
    "        print(f\"Class '{sclass}': {perc:.2f}%\")\n",
    "\n",
    "class_perc(df['survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass        0\n",
       "survived      0\n",
       "sex           0\n",
       "age         263\n",
       "sibsp         0\n",
       "parch         0\n",
       "fare          1\n",
       "embarked      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna(subset=['embarked', 'age', 'fare'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to split it into training and test (with same class distribution of survived variable in each set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_df(dataframe, seed=None, percentage=0.8):\n",
    "    \n",
    "    X = df.loc[:, dataframe.columns != 'survived']\n",
    "    y = df['survived']\n",
    "\n",
    "    return train_test_split(X, y, test_size=1-percentage, random_state=seed, stratify=y) # note the stratify parameter\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = split_df(df, seed=42, percentage=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data set:  (521, 7)\n",
      "Testing data set:  (522, 7)\n",
      "Class '1': 40.69%\n",
      "Class '0': 59.31%\n",
      "Class '0': 59.20%\n",
      "Class '1': 40.80%\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data set: \", X_train.shape)\n",
    "print(\"Testing data set: \", X_test.shape)\n",
    "class_perc(Y_train.to_frame(name='survived')[\"survived\"])\n",
    "class_perc(Y_test.to_frame(name='survived')[\"survived\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "titanic_tree = DecisionTreeClassifier(random_state=42)\n",
    "titanic_tree.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look to the performance of the classifier (by using initially Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.7241\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "predictions = titanic_tree.predict(X_test)\n",
    "print(\"Accuracy = {0:.4f}\".format(accuracy_score(Y_test, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will take a look to the tree itself. This is a bit complex since sklearn does not provide a way to visualize the models. To that end, we will need to make use of an external library: `pydotplus`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydotplus in c:\\users\\vvarg\\anaconda3\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.1 in c:\\users\\vvarg\\anaconda3\\lib\\site-packages (from pydotplus) (3.0.9)\n",
      "Requirement already satisfied: graphviz in c:\\users\\vvarg\\anaconda3\\lib\\site-packages (0.20.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install pydotplus\n",
    "\n",
    "! pip install graphviz \n",
    "# you may need to install this library directly from https://graphviz.gitlab.io/_pages/Download/Download_windows.html \n",
    "# and then uncomment following two lines\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:\\Program Files\\Graphviz\\bin'\n",
    "\n",
    "from io import StringIO\n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "\n",
    "def plot_tree(tree, feature_names):\n",
    "    dot_data = StringIO()\n",
    "    export_graphviz(tree, out_file=dot_data, feature_names=feature_names,\n",
    "                    filled=True, rounded=True,special_characters=True)\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "    return Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvocationException",
     "evalue": "GraphViz's executables not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvocationException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7672\\4239528093.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitanic_tree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7672\\2534268547.py\u001b[0m in \u001b[0;36mplot_tree\u001b[1;34m(tree, feature_names)\u001b[0m\n\u001b[0;32m     17\u001b[0m                     filled=True, rounded=True,special_characters=True)\n\u001b[0;32m     18\u001b[0m     \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_from_dot_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_png\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydotplus\\graphviz.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, prog)\u001b[0m\n\u001b[0;32m   1795\u001b[0m             self.__setattr__(\n\u001b[0;32m   1796\u001b[0m                 \u001b[1;34m'create_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfrmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1797\u001b[1;33m                 \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfrmt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1798\u001b[0m             )\n\u001b[0;32m   1799\u001b[0m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'create_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfrmt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydotplus\\graphviz.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format)\u001b[0m\n\u001b[0;32m   1957\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_graphviz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1958\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m                 raise InvocationException(\n\u001b[0m\u001b[0;32m   1960\u001b[0m                     'GraphViz\\'s executables not found')\n\u001b[0;32m   1961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvocationException\u001b[0m: GraphViz's executables not found"
     ]
    }
   ],
   "source": [
    "plot_tree(titanic_tree, X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many nodes and leaves?\n",
    "print(\"Number of nodes: \", titanic_tree.tree_.node_count)\n",
    "print(\"Number of leaves: \", titanic_tree.get_n_leaves())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will plot the feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.bar(X_train.columns, titanic_tree.feature_importances_)\n",
    "plt.title('Feature Importance', fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruning the tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will prune the tree to see if we can improve performance.\n",
    "\n",
    "There are different Pruning Parameters:\n",
    "\n",
    " - max_leaf_nodes: Reduce the number of leaf nodes\n",
    " - min_samples_leaf: Restrict the size of sample leaf. Minimum sample size in terminal nodes can be fixed to 30, 100, 300 or 5% of total \n",
    " - max_depth: Reduce the depth of the tree to build a generalized tree. Set the depth of the tree to 3, 5, 10 depending after verification on test data\n",
    "\n",
    "Let's focus on the depth of the tree. We will test different depth thresholds via CV by using the `GridSearchCV` provided by sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'max_depth': range(1,16)} # 15 different depth levels\n",
    "\n",
    "titanic_tree_pruned_cv = GridSearchCV(titanic_tree, \n",
    "                   param_grid,\n",
    "                   scoring='accuracy',\n",
    "                   cv=5 , n_jobs=1, verbose=1)\n",
    "\n",
    "titanic_tree_pruned_cv.fit(X_train,Y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(titanic_tree_pruned_cv.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = titanic_tree_pruned_cv.cv_results_['mean_test_score']\n",
    "stds = titanic_tree_pruned_cv.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, titanic_tree_pruned_cv.cv_results_['params']):\n",
    "    print(\"Accuracy = %0.3f (+/%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,10))\n",
    "plt.errorbar(range(1,16,1), [m for m in means], yerr=stds, fmt='--o')\n",
    "plt.title('Accuracy for different Depths', fontsize=20)\n",
    "plt.xlabel(\"Depth\", fontsize=16)\n",
    "plt.ylabel(\"Accuracy\", fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen in the plot, the optimal value for the depth of the decision tree is 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_tree_pruned = DecisionTreeClassifier(random_state=42, max_depth=3)\n",
    "tree=titanic_tree_pruned.fit(X_train, Y_train)\n",
    "predictions = titanic_tree_pruned.predict(X_test)\n",
    "print(\"Accuracy = {0:.4f}\".format(accuracy_score(Y_test, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We have increase the accuracy with a smaller tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many nodes and leaves?\n",
    "print(\"Number of nodes: \", titanic_tree_pruned.tree_.node_count)\n",
    "print(\"Number of leaves: \", titanic_tree_pruned.get_n_leaves())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "text_representation = tree.export_text(titanic_tree_pruned)\n",
    "print(text_representation)\n",
    "with open(\"decision_tree.log\", \"w\") as fout:\n",
    "    fout.write(text_representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to deep down a bit more on the tree.<BR>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "# DOT data\n",
    "dot_data = tree.export_graphviz(titanic_tree_pruned, out_file=None, \n",
    "                                class_names=[\"No\",\"Yes\"],\n",
    "                                feature_names=X_train.columns,  \n",
    "                                filled=True)\n",
    "\n",
    "# Draw graph\n",
    "graph = graphviz.Source(dot_data, format=\"png\") \n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save it into a high resolution image\n",
    "graph.render(\"titanic_tree_graphivz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option:\n",
    "we need to install the powerful library *dtreeviz* for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ! pip install dtreeviz\n",
    "import dtreeviz\n",
    "\n",
    "viz_cmodel = dtreeviz.model(titanic_tree_pruned,\n",
    "                           X_train=X_train,\n",
    "                           y_train=Y_train,\n",
    "                           feature_names=X_train.columns,\n",
    "                           target_name='survived')\n",
    "viz_cmodel.view(scale=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display now frequencies for each node.<BR>\n",
    "We can see node id=6 is the one with maximum amount of people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_cmodel.leaf_sizes(figsize=(12,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare it with target classes\n",
    "viz_cmodel.ctree_leaf_distributions(figsize=(12,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore that node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_cmodel.node_stats(node_id=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And highlight it in the tree so that we can take a closer look at it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_train[X_train.columns].iloc[1]\n",
    "viz_cmodel.view(x=x, scale=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's going to analyze model performance (on test data set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print Confusion Matrix and Classification Report\n",
    "def model_perf(model, Y_test, Y_predict, algorithm, df_cm, df_perf, ax=None, plot = True):\n",
    "    # confusion_matrix\n",
    "    conf_mat = confusion_matrix(Y_test, Y_predict)\n",
    "    \n",
    "    # get accuracy of model\n",
    "    acc_score = accuracy_score(Y_test, Y_predict)\n",
    "    print(f\"Accuracy of {algorithm} for Test data is {acc_score*100}\\n\")\n",
    "\n",
    "    # get F1-score of model\n",
    "    f1score = f1_score(Y_test, Y_predict) \n",
    "    print(f\"F1-score of {algorithm} for Test data is {f1score*100}\\n\")\n",
    "    \n",
    "    # get the classification report\n",
    "    class_report = classification_report(Y_test, Y_predict)\n",
    "    print(f\"Classification report for {algorithm} is: \\n {class_report}\")\n",
    "    \n",
    "    # AUC Calculations - false positive rates, true positive rates and thresholds\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(Y_test, Y_predict, pos_label=1)\n",
    "    \n",
    "    #area_under_curve\n",
    "    roc_auc = round(metrics.auc(fpr, tpr)*100,2)\n",
    "    print(f\"AUC for {algorithm}: {roc_auc}\\n\")\n",
    "    \n",
    "    #Train Accuracy score\n",
    "    train_acc = round(model.score(X_train,Y_train) * 100,2)\n",
    "\n",
    "    #Test Accuracy score\n",
    "    test_acc = round(model.score(X_test,Y_test) * 100,2)\n",
    "\n",
    "    precision,recall,fscore,support = precision_recall_fscore_support(Y_test,Y_predict)\n",
    "\n",
    "    #Appending into the dataframe\n",
    "    df_perf = df_perf.append({'Model' : algorithm,'Train Accuracy' : train_acc,'Test Accuracy' : test_acc,\n",
    "                          'F1-Score' : fscore[1],'Recall' : recall[1], 'Precision' : precision[1], 'AUC' : roc_auc}, ignore_index=True)\n",
    "\n",
    "    df_cm = df_cm.append({\"Model\" : algorithm, \"True Positives\" : conf_mat[1][1], \"True Negatives\" : conf_mat[0][0],\n",
    "                      \"False Positives\" : conf_mat[0][1], \"False Negatives\" : conf_mat[1][0]}, ignore_index=True, sort=False)\n",
    "\n",
    "##########################################--PLOT---###########################################\n",
    "    if plot:\n",
    "        def conf_plot1(ax = None):\n",
    "            if ax is None:\n",
    "                fig, ax = plt.subplots()\n",
    "            # For label annotations in confusion_matrix\n",
    "            label_names = ['True N','False N','False P','True P']\n",
    "            label_counts = ['{0:0.0f}'.format(value) for value in conf_mat.flatten()]\n",
    "            labels = [f'{v1}\\n{v2}' for v1, v2 in zip(label_names,label_counts)]\n",
    "            labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "            # Draw heatmap using confusion matrix\n",
    "            sns.heatmap(conf_mat, annot=labels, fmt='')\n",
    "            ax.set_xlabel('Actual Values')\n",
    "            ax.set_ylabel('Predicted Values')\n",
    "            #ax.show()\n",
    "\n",
    "        #Line plot for ROC curve using fpr and tpr value\n",
    "        def roc_plot2(ax = None):\n",
    "            if ax is None:\n",
    "                fig, ax = plt.subplots()\n",
    "            ax.plot(fpr, tpr, color='red', label = 'AUC = %0.3f' % roc_auc)  \n",
    "            ax.set_title('Receiver Operating Characteristic (ROC)')    \n",
    "            ax.legend(loc = 'lower right')\n",
    "            ax.plot([0, 1], [0, 1],linestyle='--') #Intersection line\n",
    "            ax.set_xlabel('False Positive Rate')\n",
    "            ax.set_ylabel('True Positive Rate')\n",
    "            ax.set_xlim([0,1])\n",
    "            ax.set_ylim([0,1])\n",
    "            ax.set_xticks([i for i in np.arange(0,1.1,0.1)])\n",
    "            ax.set_yticks([i for i in np.arange(0,1.1,0.1)])\n",
    "        \n",
    "        prec, rec, thres = precision_recall_curve(Y_test, Y_predict)\n",
    "        prec, rec, thres = prec.tolist(), rec.tolist(), thres.tolist()\n",
    "        prec.pop()\n",
    "        rec.pop()\n",
    "            \n",
    "        def rec_plot3(ax = None):\n",
    "            if ax is None:\n",
    "                fig, ax = plt.subplots()\n",
    "            #Plot Precision-Recall curve\n",
    "            fig, axis = (None, ax) if ax else plt.subplots()\n",
    "            axis_twin = axis.twinx()\n",
    "\n",
    "            #Threshold vs Precision\n",
    "            sns.lineplot(x = thres, y = prec, label='Precision', ax=axis)\n",
    "            axis.set_xlabel('Threshold')\n",
    "            axis.set_ylabel('Precision')\n",
    "            axis.legend(loc='lower left')\n",
    "\n",
    "            #Threshold vs Recall\n",
    "            sns.lineplot(x = thres, y = rec, color='limegreen', label='Recall', ax=axis_twin)\n",
    "            axis_twin.set_ylabel('Recall')\n",
    "            axis_twin.set_ylim(0, 1)\n",
    "            axis_twin.legend(bbox_to_anchor=(0.32, 0.20),loc='lower right')\n",
    "\n",
    "            axis.set_xlim(0, 1)\n",
    "            axis.set_ylim(0, 1)\n",
    "            axis.set_title('Precision Vs Recall')\n",
    "        \n",
    "                    \n",
    "        fig = plt.figure(figsize = (15,4))\n",
    "        ax1 = fig.add_subplot(1,3,1)\n",
    "        conf_plot1(ax1)\n",
    "        ax2 = fig.add_subplot(1,3,2)\n",
    "        roc_plot2(ax2)\n",
    "        axis = fig.add_subplot(1,3,3)\n",
    "        rec_plot3(axis)\n",
    "    \n",
    "    \n",
    "    return df_cm, df_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install model-perf --upgrade\n",
    "# import model_perf\n",
    "\n",
    "# Dataframe to store Model Performance Results\n",
    "perf_cols = ['Model','Train Accuracy','Test Accuracy','F1-Score','Recall','Precision', 'AUC']\n",
    "df_perf = pd.DataFrame(columns = perf_cols)\n",
    "\n",
    "# DataFrame for Confusion matrix\n",
    "conf_mat_cols = ['Model','False Negatives','False Positives','True Negatives','True Positives']\n",
    "df_cm = pd.DataFrame(columns = conf_mat_cols)\n",
    "\n",
    "# DataFrame for cross validation scores\n",
    "cv_cols = ['Model','Best_Cross_Val_Score']\n",
    "df_cv = pd.DataFrame(columns = cv_cols)\n",
    "\n",
    "#Draw Model Performace, Confusion Matrix and Classification Report\n",
    "df_cm, df_perf = model_perf(titanic_tree_pruned, Y_test, predictions, \"Classification Tree\", df_cm, df_perf, plot = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
